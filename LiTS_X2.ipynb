{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File volume-0.nii size reduced by 92.68%\n",
      "File volume-1.nii size reduced by 92.37%\n",
      "File volume-10.nii size reduced by 90.38%\n",
      "File volume-100.nii size reduced by 89.55%\n",
      "File volume-101.nii size reduced by 90.06%\n",
      "File volume-102.nii size reduced by 89.65%\n",
      "File volume-103.nii size reduced by 90.52%\n",
      "File volume-104.nii size reduced by 92.15%\n",
      "File volume-105.nii size reduced by 90.29%\n",
      "File volume-106.nii size reduced by 92.12%\n",
      "Processed batch 1\n",
      "File volume-107.nii size reduced by 91.93%\n",
      "File volume-108.nii size reduced by 91.75%\n",
      "File volume-109.nii size reduced by 91.69%\n",
      "File volume-11.nii size reduced by 89.58%\n",
      "File volume-110.nii size reduced by 91.85%\n",
      "File volume-12.nii size reduced by 90.51%\n",
      "File volume-13.nii size reduced by 91.13%\n",
      "File volume-14.nii size reduced by 90.45%\n",
      "File volume-15.nii size reduced by 90.45%\n",
      "File volume-16.nii size reduced by 92.31%\n",
      "Processed batch 2\n",
      "File volume-17.nii size reduced by 92.02%\n",
      "File volume-18.nii size reduced by 92.53%\n",
      "File volume-19.nii size reduced by 90.19%\n",
      "File volume-2.nii size reduced by 90.10%\n",
      "File volume-20.nii size reduced by 90.66%\n",
      "File volume-21.nii size reduced by 90.77%\n",
      "File volume-22.nii size reduced by 92.79%\n",
      "File volume-23.nii size reduced by 90.44%\n",
      "File volume-24.nii size reduced by 90.42%\n",
      "File volume-25.nii size reduced by 91.46%\n",
      "Processed batch 3\n",
      "File volume-26.nii size reduced by 91.47%\n",
      "File volume-27.nii size reduced by 90.65%\n",
      "File volume-28.nii size reduced by 91.59%\n",
      "File volume-29.nii size reduced by 92.51%\n",
      "File volume-3.nii size reduced by 90.08%\n",
      "File volume-30.nii size reduced by 91.31%\n",
      "File volume-31.nii size reduced by 90.79%\n",
      "File volume-32.nii size reduced by 91.28%\n",
      "File volume-33.nii size reduced by 91.19%\n",
      "File volume-34.nii size reduced by 92.44%\n",
      "Processed batch 4\n",
      "File volume-35.nii size reduced by 92.08%\n",
      "File volume-36.nii size reduced by 91.16%\n",
      "File volume-37.nii size reduced by 91.79%\n",
      "File volume-38.nii size reduced by 91.73%\n",
      "File volume-39.nii size reduced by 91.99%\n",
      "File volume-4.nii size reduced by 91.99%\n",
      "File volume-40.nii size reduced by 91.85%\n",
      "File volume-41.nii size reduced by 91.62%\n",
      "File volume-42.nii size reduced by 92.36%\n",
      "File volume-43.nii size reduced by 91.54%\n",
      "Processed batch 5\n",
      "File volume-44.nii size reduced by 91.84%\n",
      "File volume-45.nii size reduced by 91.44%\n",
      "File volume-46.nii size reduced by 92.06%\n",
      "File volume-47.nii size reduced by 92.96%\n",
      "File volume-48.nii size reduced by 92.76%\n",
      "File volume-49.nii size reduced by 92.30%\n",
      "File volume-5.nii size reduced by 91.69%\n",
      "File volume-50.nii size reduced by 92.84%\n",
      "File volume-51.nii size reduced by 91.81%\n",
      "File volume-52.nii size reduced by 92.61%\n",
      "Processed batch 6\n",
      "File volume-53.nii size reduced by 92.24%\n",
      "File volume-54.nii size reduced by 96.27%\n",
      "File volume-55.nii size reduced by 96.04%\n",
      "File volume-56.nii size reduced by 90.96%\n",
      "File volume-57.nii size reduced by 96.01%\n",
      "File volume-58.nii size reduced by 90.91%\n",
      "File volume-59.nii size reduced by 90.59%\n",
      "File volume-6.nii size reduced by 91.11%\n",
      "File volume-60.nii size reduced by 90.73%\n",
      "File volume-61.nii size reduced by 91.17%\n",
      "Processed batch 7\n",
      "File volume-62.nii size reduced by 91.19%\n",
      "File volume-63.nii size reduced by 96.09%\n",
      "File volume-64.nii size reduced by 90.89%\n",
      "File volume-65.nii size reduced by 91.83%\n",
      "File volume-66.nii size reduced by 90.39%\n",
      "File volume-67.nii size reduced by 91.26%\n",
      "File volume-68.nii size reduced by 95.89%\n",
      "File volume-69.nii size reduced by 95.21%\n",
      "File volume-7.nii size reduced by 90.26%\n",
      "File volume-70.nii size reduced by 95.97%\n",
      "Processed batch 8\n",
      "File volume-71.nii size reduced by 94.96%\n",
      "File volume-72.nii size reduced by 95.99%\n",
      "File volume-73.nii size reduced by 96.18%\n",
      "File volume-74.nii size reduced by 95.98%\n",
      "File volume-75.nii size reduced by 95.42%\n",
      "File volume-76.nii size reduced by 96.10%\n",
      "File volume-77.nii size reduced by 92.27%\n",
      "File volume-78.nii size reduced by 96.36%\n",
      "File volume-79.nii size reduced by 95.48%\n",
      "File volume-8.nii size reduced by 90.90%\n",
      "Processed batch 9\n",
      "File volume-80.nii size reduced by 95.57%\n",
      "File volume-81.nii size reduced by 96.02%\n",
      "File volume-82.nii size reduced by 91.83%\n",
      "File volume-83.nii size reduced by 90.28%\n",
      "File volume-84.nii size reduced by 89.71%\n",
      "File volume-85.nii size reduced by 89.51%\n",
      "File volume-86.nii size reduced by 89.55%\n",
      "File volume-87.nii size reduced by 91.81%\n",
      "File volume-88.nii size reduced by 91.71%\n",
      "File volume-89.nii size reduced by 91.60%\n",
      "Processed batch 10\n",
      "File volume-9.nii size reduced by 90.58%\n",
      "File volume-90.nii size reduced by 91.74%\n",
      "File volume-91.nii size reduced by 91.92%\n",
      "File volume-92.nii size reduced by 91.63%\n",
      "File volume-93.nii size reduced by 91.62%\n",
      "File volume-94.nii size reduced by 90.44%\n",
      "File volume-95.nii size reduced by 91.95%\n",
      "File volume-96.nii size reduced by 90.20%\n",
      "File volume-97.nii size reduced by 90.13%\n",
      "File volume-98.nii size reduced by 90.60%\n",
      "Processed batch 11\n",
      "File volume-99.nii size reduced by 90.75%\n",
      "Processed batch 12\n",
      "Processing completed\n",
      "\n",
      "Total processing time: 535.69 seconds\n",
      "Memory usage: 1164.37 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import time\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "# Set watchdog timer for performance monitoring\n",
    "start_time = time.time()\n",
    "\n",
    "def compress_nifti(input_file, output_file):\n",
    "    \"\"\"Compress NIFTI file using gzip\"\"\"\n",
    "    with open(input_file, 'rb') as f_in:\n",
    "        with gzip.open(output_file, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "    return output_file\n",
    "\n",
    "def process_nifti_files(input_path, output_path, batch_size=10):\n",
    "    \"\"\"\n",
    "    Process NIFTI files and create compressed batches\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create output directory if it doesn't exist\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "        \n",
    "        # Get all .nii and .nii.gz files\n",
    "        nifti_files = []\n",
    "        for ext in ('*.nii', '*.nii.gz'):\n",
    "            nifti_files.extend(Path(input_path).glob(ext))\n",
    "        \n",
    "        if not nifti_files:\n",
    "            print(\"No NIFTI files found in the input directory\")\n",
    "            return\n",
    "            \n",
    "        # Process files in batches\n",
    "        for batch_num, i in enumerate(range(0, len(nifti_files), batch_size)):\n",
    "            batch_files = nifti_files[i:i + batch_size]\n",
    "            batch_dir = os.path.join(output_path, f'batch_{batch_num+1}')\n",
    "            os.makedirs(batch_dir, exist_ok=True)\n",
    "            \n",
    "            for file_path in batch_files:\n",
    "                try:\n",
    "                    # Load NIFTI file\n",
    "                    img = nib.load(str(file_path))\n",
    "                    data = img.get_fdata()\n",
    "                    \n",
    "                    # Downsample the data to reduce size (by factor of 2)\n",
    "                    data = data[::2, ::2, ::2]\n",
    "                    \n",
    "                    # Convert to float16 to reduce memory usage\n",
    "                    data = data.astype(np.float32)\n",
    "                    \n",
    "                    # Normalize data to [0,1]\n",
    "                    data = (data - data.min()) / (data.max() - data.min())\n",
    "                    \n",
    "                    # Create new NIFTI image with processed data\n",
    "                    new_img = nib.Nifti1Image(data, img.affine)\n",
    "                    \n",
    "                    # Save to temporary uncompressed file\n",
    "                    temp_output = os.path.join(batch_dir, f\"temp_{file_path.stem}.nii\")\n",
    "                    nib.save(new_img, temp_output)\n",
    "                    \n",
    "                    # Compress the file\n",
    "                    final_output = os.path.join(batch_dir, f\"{file_path.stem}.nii.gz\")\n",
    "                    compress_nifti(temp_output, final_output)\n",
    "                    \n",
    "                    # Remove temporary file\n",
    "                    os.remove(temp_output)\n",
    "                    \n",
    "                    # Print file size reduction\n",
    "                    original_size = os.path.getsize(file_path)\n",
    "                    compressed_size = os.path.getsize(final_output)\n",
    "                    reduction = ((original_size - compressed_size) / original_size) * 100\n",
    "                    print(f\"File {file_path.name} size reduced by {reduction:.2f}%\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {file_path}: {str(e)}\")\n",
    "                    continue\n",
    "                    \n",
    "            print(f\"Processed batch {batch_num+1}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in batch processing: {str(e)}\")\n",
    "    finally:\n",
    "        print(\"Processing completed\")\n",
    "\n",
    "# Set input and output paths\n",
    "input_path = r\"C:\\Users\\alibh\\.cache\\kagglehub\\datasets\\javariatahir\\litstrain-val\\versions\\1\\LiTS(train_test)\\train_CT\"\n",
    "output_path = os.path.join(os.path.dirname(input_path), \"compressed_batches\")\n",
    "\n",
    "# Process the files\n",
    "process_nifti_files(input_path, output_path)\n",
    "\n",
    "# Performance monitoring\n",
    "end_time = time.time()\n",
    "print(f\"\\nTotal processing time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Monitor memory usage\n",
    "import psutil\n",
    "process = psutil.Process()\n",
    "memory_info = process.memory_info()\n",
    "print(f\"Memory usage: {memory_info.rss / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "# Set up watchdog for monitoring file changes\n",
    "class FileHandler(FileSystemEventHandler):\n",
    "    def on_modified(self, event):\n",
    "        if not event.is_directory:\n",
    "            print(f\"File {event.src_path} has been modified\")\n",
    "\n",
    "observer = Observer()\n",
    "event_handler = FileHandler()\n",
    "observer.schedule(event_handler, output_path, recursive=True)\n",
    "observer.start()\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "except KeyboardInterrupt:\n",
    "    observer.stop()\n",
    "finally:\n",
    "    observer.join()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Files in output directory:\n",
      "File: volume-0.nii.gz, Size: 2.75 MB\n",
      "File: volume-1.nii.gz, Size: 4.69 MB\n",
      "File: volume-10.nii.gz, Size: 24.09 MB\n",
      "File: volume-100.nii.gz, Size: 35.79 MB\n",
      "File: volume-101.nii.gz, Size: 33.94 MB\n",
      "File: volume-102.nii.gz, Size: 35.02 MB\n",
      "File: volume-103.nii.gz, Size: 32.39 MB\n",
      "File: volume-104.nii.gz, Size: 30.65 MB\n",
      "File: volume-105.nii.gz, Size: 47.87 MB\n",
      "File: volume-106.nii.gz, Size: 30.39 MB\n",
      "File: volume-80.nii.gz, Size: 9.62 MB\n",
      "File: volume-81.nii.gz, Size: 13.64 MB\n",
      "File: volume-82.nii.gz, Size: 21.20 MB\n",
      "File: volume-83.nii.gz, Size: 42.35 MB\n",
      "File: volume-84.nii.gz, Size: 37.73 MB\n",
      "File: volume-85.nii.gz, Size: 33.03 MB\n",
      "File: volume-86.nii.gz, Size: 33.79 MB\n",
      "File: volume-87.nii.gz, Size: 36.68 MB\n",
      "File: volume-88.nii.gz, Size: 33.61 MB\n",
      "File: volume-89.nii.gz, Size: 32.16 MB\n",
      "File: volume-9.nii.gz, Size: 25.85 MB\n",
      "File: volume-90.nii.gz, Size: 31.02 MB\n",
      "File: volume-91.nii.gz, Size: 30.34 MB\n",
      "File: volume-92.nii.gz, Size: 34.97 MB\n",
      "File: volume-93.nii.gz, Size: 29.17 MB\n",
      "File: volume-94.nii.gz, Size: 43.84 MB\n",
      "File: volume-95.nii.gz, Size: 33.86 MB\n",
      "File: volume-96.nii.gz, Size: 35.38 MB\n",
      "File: volume-97.nii.gz, Size: 33.12 MB\n",
      "File: volume-98.nii.gz, Size: 30.32 MB\n",
      "File: volume-99.nii.gz, Size: 29.09 MB\n",
      "File: volume-107.nii.gz, Size: 31.12 MB\n",
      "File: volume-108.nii.gz, Size: 35.30 MB\n",
      "File: volume-109.nii.gz, Size: 31.40 MB\n",
      "File: volume-11.nii.gz, Size: 24.28 MB\n",
      "File: volume-110.nii.gz, Size: 33.27 MB\n",
      "File: volume-12.nii.gz, Size: 21.58 MB\n",
      "File: volume-13.nii.gz, Size: 26.85 MB\n",
      "File: volume-14.nii.gz, Size: 28.09 MB\n",
      "File: volume-15.nii.gz, Size: 26.99 MB\n",
      "File: volume-16.nii.gz, Size: 26.49 MB\n",
      "File: volume-17.nii.gz, Size: 32.96 MB\n",
      "File: volume-18.nii.gz, Size: 31.58 MB\n",
      "File: volume-19.nii.gz, Size: 26.82 MB\n",
      "File: volume-2.nii.gz, Size: 25.58 MB\n",
      "File: volume-20.nii.gz, Size: 26.79 MB\n",
      "File: volume-21.nii.gz, Size: 20.16 MB\n",
      "File: volume-22.nii.gz, Size: 8.91 MB\n",
      "File: volume-23.nii.gz, Size: 18.70 MB\n",
      "File: volume-24.nii.gz, Size: 13.22 MB\n",
      "File: volume-25.nii.gz, Size: 25.65 MB\n",
      "File: volume-26.nii.gz, Size: 28.47 MB\n",
      "File: volume-27.nii.gz, Size: 40.26 MB\n",
      "File: volume-28.nii.gz, Size: 5.42 MB\n",
      "File: volume-29.nii.gz, Size: 6.44 MB\n",
      "File: volume-3.nii.gz, Size: 26.49 MB\n",
      "File: volume-30.nii.gz, Size: 8.69 MB\n",
      "File: volume-31.nii.gz, Size: 4.19 MB\n",
      "File: volume-32.nii.gz, Size: 6.06 MB\n",
      "File: volume-33.nii.gz, Size: 5.95 MB\n",
      "File: volume-34.nii.gz, Size: 5.70 MB\n",
      "File: volume-35.nii.gz, Size: 4.91 MB\n",
      "File: volume-36.nii.gz, Size: 4.91 MB\n",
      "File: volume-37.nii.gz, Size: 5.01 MB\n",
      "File: volume-38.nii.gz, Size: 5.46 MB\n",
      "File: volume-39.nii.gz, Size: 10.42 MB\n",
      "File: volume-4.nii.gz, Size: 33.70 MB\n",
      "File: volume-40.nii.gz, Size: 4.97 MB\n",
      "File: volume-41.nii.gz, Size: 4.74 MB\n",
      "File: volume-42.nii.gz, Size: 4.77 MB\n",
      "File: volume-43.nii.gz, Size: 6.55 MB\n",
      "File: volume-44.nii.gz, Size: 4.85 MB\n",
      "File: volume-45.nii.gz, Size: 3.17 MB\n",
      "File: volume-46.nii.gz, Size: 4.92 MB\n",
      "File: volume-47.nii.gz, Size: 7.92 MB\n",
      "File: volume-48.nii.gz, Size: 8.83 MB\n",
      "File: volume-49.nii.gz, Size: 9.78 MB\n",
      "File: volume-5.nii.gz, Size: 22.31 MB\n",
      "File: volume-50.nii.gz, Size: 8.59 MB\n",
      "File: volume-51.nii.gz, Size: 9.30 MB\n",
      "File: volume-52.nii.gz, Size: 8.75 MB\n",
      "File: volume-53.nii.gz, Size: 4.07 MB\n",
      "File: volume-54.nii.gz, Size: 3.58 MB\n",
      "File: volume-55.nii.gz, Size: 7.60 MB\n",
      "File: volume-56.nii.gz, Size: 10.81 MB\n",
      "File: volume-57.nii.gz, Size: 14.60 MB\n",
      "File: volume-58.nii.gz, Size: 9.63 MB\n",
      "File: volume-59.nii.gz, Size: 10.17 MB\n",
      "File: volume-6.nii.gz, Size: 23.03 MB\n",
      "File: volume-60.nii.gz, Size: 11.30 MB\n",
      "File: volume-61.nii.gz, Size: 8.53 MB\n",
      "File: volume-62.nii.gz, Size: 8.28 MB\n",
      "File: volume-63.nii.gz, Size: 4.07 MB\n",
      "File: volume-64.nii.gz, Size: 10.48 MB\n",
      "File: volume-65.nii.gz, Size: 20.95 MB\n",
      "File: volume-66.nii.gz, Size: 4.13 MB\n",
      "File: volume-67.nii.gz, Size: 7.21 MB\n",
      "File: volume-68.nii.gz, Size: 10.93 MB\n",
      "File: volume-69.nii.gz, Size: 11.73 MB\n",
      "File: volume-7.nii.gz, Size: 26.34 MB\n",
      "File: volume-70.nii.gz, Size: 13.41 MB\n",
      "File: volume-71.nii.gz, Size: 4.73 MB\n",
      "File: volume-72.nii.gz, Size: 3.73 MB\n",
      "File: volume-73.nii.gz, Size: 4.62 MB\n",
      "File: volume-74.nii.gz, Size: 4.30 MB\n",
      "File: volume-75.nii.gz, Size: 4.07 MB\n",
      "File: volume-76.nii.gz, Size: 6.56 MB\n",
      "File: volume-77.nii.gz, Size: 3.63 MB\n",
      "File: volume-78.nii.gz, Size: 7.20 MB\n",
      "File: volume-79.nii.gz, Size: 6.64 MB\n",
      "File: volume-8.nii.gz, Size: 24.61 MB\n",
      "\n",
      "Memory usage breakdown:\n",
      "Error checking files: name 'gc' is not defined\n",
      "\n",
      "Time taken to check files: 0.03 seconds\n"
     ]
    }
   ],
   "source": [
    "# Get list of files in memory and storage\n",
    "def check_files():\n",
    "    try:\n",
    "        # Check files in output directory\n",
    "        print(\"\\nFiles in output directory:\")\n",
    "        for root, dirs, files in os.walk(output_path):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                file_size = os.path.getsize(file_path) / (1024 * 1024) # Size in MB\n",
    "                print(f\"File: {file}, Size: {file_size:.2f} MB\")\n",
    "                \n",
    "        # Check memory usage per file loaded\n",
    "        print(\"\\nMemory usage breakdown:\")\n",
    "        for obj in gc.get_objects():\n",
    "            if isinstance(obj, np.ndarray):\n",
    "                size = obj.nbytes / (1024 * 1024) # Size in MB\n",
    "                print(f\"Array shape: {obj.shape}, Size: {size:.2f} MB\")\n",
    "                \n",
    "        # Total memory stats\n",
    "        memory = psutil.virtual_memory()\n",
    "        print(f\"\\nTotal memory usage: {memory.percent}%\")\n",
    "        print(f\"Available memory: {memory.available/(1024*1024):.2f} MB\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error checking files: {str(e)}\")\n",
    "\n",
    "# Set watchdog timer for performance\n",
    "start = time.time()\n",
    "check_files()\n",
    "end = time.time()\n",
    "print(f\"\\nTime taken to check files: {end-start:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'termcolor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import required libraries\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers, models\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\__init__.py:49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[0;32m     47\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\_api\\v2\\__internal__\\autograph\\__init__.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_convert \u001b[38;5;66;03m# line: 493\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m operators\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconverters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m asserts\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconverters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m break_statements\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconverters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m call_trees\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\autograph\\converters\\asserts.py:19\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Converts assert statements to their corresponding TF calls.\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgast\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m converter\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyct\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m templates\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAssertTransformer\u001b[39;00m(converter\u001b[38;5;241m.\u001b[39mBase):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\autograph\\core\\converter.py:68\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyct\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parser\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyct\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m templates\n\u001b[1;32m---> 68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyct\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transformer\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# TODO(mdan): These contexts can be refactored into first class objects.\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# For example, we could define Program and Entity abstractions that hold on\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# to the actual entity and have conversion methods.\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Add a test specific to this converter.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\autograph\\pyct\\transformer.py:24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyct\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m anno\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyct\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parser\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyct\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pretty_printer\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyct\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m templates\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAnalysisLevel\u001b[39;00m(enum\u001b[38;5;241m.\u001b[39mIntEnum):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\autograph\\pyct\\pretty_printer.py:18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Print an AST tree in a form more readable than ast.dump.\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgast\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtermcolor\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mPrettyPrinter\u001b[39;00m(gast\u001b[38;5;241m.\u001b[39mNodeVisitor):\n\u001b[0;32m     22\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Print AST nodes.\"\"\"\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'termcolor'"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler\n",
    "import time\n",
    "import termcolor as tc\n",
    "\n",
    "# Set watchdog timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Define model architecture for liver/tumor detection\n",
    "def create_model(input_shape=(256, 256, 3)):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, 3, activation='relu', padding='same', input_shape=input_shape),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(64, 3, activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(128, 3, activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(256, 3, activation='relu', padding='same'),\n",
    "        layers.UpSampling2D(),\n",
    "        layers.Conv2D(128, 3, activation='relu', padding='same'),\n",
    "        layers.UpSampling2D(),\n",
    "        layers.Conv2D(64, 3, activation='relu', padding='same'),\n",
    "        layers.UpSampling2D(),\n",
    "        layers.Conv2D(32, 3, activation='relu', padding='same'),\n",
    "        layers.Conv2D(1, 1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Load and preprocess data in batches\n",
    "def load_data_batch(batch_size=32):\n",
    "    # Assuming data is stored in output_path\n",
    "    images = []\n",
    "    masks = []\n",
    "    \n",
    "    for root, _, files in os.walk(output_path):\n",
    "        image_files = [f for f in files if f.endswith('.npy') and 'mask' not in f]\n",
    "        mask_files = [f for f in files if f.endswith('.npy') and 'mask' in f]\n",
    "        \n",
    "        for i in range(0, len(image_files), batch_size):\n",
    "            batch_images = image_files[i:i + batch_size]\n",
    "            batch_masks = mask_files[i:i + batch_size]\n",
    "            \n",
    "            for img_file, mask_file in zip(batch_images, batch_masks):\n",
    "                try:\n",
    "                    img = np.load(os.path.join(root, img_file))\n",
    "                    mask = np.load(os.path.join(root, mask_file))\n",
    "                    \n",
    "                    # Resize to standard size\n",
    "                    img = cv2.resize(img, (256, 256))\n",
    "                    mask = cv2.resize(mask, (256, 256))\n",
    "                    \n",
    "                    images.append(img)\n",
    "                    masks.append(mask)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading file {img_file}: {str(e)}\")\n",
    "                    continue\n",
    "                    \n",
    "            yield np.array(images), np.array(masks)\n",
    "            images = []\n",
    "            masks = []\n",
    "\n",
    "# Initialize model\n",
    "model = create_model()\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training parameters\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# Train model with batch generator\n",
    "try:\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "        batch_generator = load_data_batch(BATCH_SIZE)\n",
    "        \n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(batch_generator):\n",
    "            if len(X_batch) == 0:\n",
    "                continue\n",
    "                \n",
    "            # Monitor memory usage\n",
    "            memory = psutil.virtual_memory()\n",
    "            if memory.percent > 90:\n",
    "                print(\"Warning: High memory usage detected!\")\n",
    "                gc.collect()\n",
    "            \n",
    "            history = model.fit(X_batch, y_batch, batch_size=BATCH_SIZE, verbose=1)\n",
    "            \n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"Batch {batch_idx} - Loss: {history.history['loss'][0]:.4f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Training error: {str(e)}\")\n",
    "\n",
    "# Function to detect and visualize tumors\n",
    "def detect_tumors(image):\n",
    "    processed_img = cv2.resize(image, (256, 256))\n",
    "    prediction = model.predict(np.expand_dims(processed_img, 0))[0]\n",
    "    \n",
    "    # Draw bounding boxes for detected tumors\n",
    "    threshold = 0.5\n",
    "    binary_mask = (prediction > threshold).astype(np.uint8)\n",
    "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    result_img = image.copy()\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        cv2.rectangle(result_img, (x, y), (x+w, y+h), (0, 0, 255), 2)  # Red box\n",
    "    \n",
    "    return result_img\n",
    "\n",
    "# Test the model on a sample image\n",
    "try:\n",
    "    sample_files = os.listdir(output_path)[:5]  # Get first 5 images\n",
    "    for file in sample_files:\n",
    "        if file.endswith('.npy') and 'mask' not in file:\n",
    "            img = np.load(os.path.join(output_path, file))\n",
    "            result = detect_tumors(img)\n",
    "            \n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.imshow(img)\n",
    "            plt.title('Original Image')\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.imshow(result)\n",
    "            plt.title('Detected Tumors')\n",
    "            plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in tumor detection: {str(e)}\")\n",
    "\n",
    "# Performance metrics\n",
    "end_time = time.time()\n",
    "print(f\"\\nTotal execution time: {end_time - start_time:.2f} seconds\")\n",
    "print(f\"Final memory usage: {psutil.virtual_memory().percent}%\")\n",
    "print(f\"Available memory: {psutil.virtual_memory().available/(1024*1024):.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: termcolor in c:\\users\\alibh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install termcolor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
